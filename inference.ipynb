{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "83fe0e20-8214-443e-970e-7abdc1d3ab0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # 警告扰人，手动封存\n",
    "import torch\n",
    "from DataLoader_s2s import Exampledataset,collate_func\n",
    "from model import S2sTransformer,seq_generation_loss\n",
    "from AF_LSTM import AF_LSTM\n",
    "from utils.vocabulary import Vocab\n",
    "import logging\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import textstat\n",
    "from utils.Word2Vec_emb import Word_Embedding\n",
    "from rouge import Rouge\n",
    "import json, os, math\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import heapq\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from nltk.translate import bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2588c1cc-6d3b-4495-b2c5-81f436a439ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jsonloader(filename):\n",
    "    # 将数据加载到一个列表中\n",
    "    file = open(filename, 'r', encoding='utf-8')\n",
    "    entity_list=[]#实体\n",
    "    news_list = []#新闻\n",
    "    date_list = []#日期\n",
    "    vnames_list = []#新闻所含实体列表\n",
    "    label_list=[]#评论\n",
    "    title_list=[]#标题\n",
    "    label_score_list=[]#评论情感分数\n",
    "    for line in file.readlines():\n",
    "        pop_dict = json.loads(line)\n",
    "        entity=pop_dict['entity']\n",
    "        date = pop_dict['date']\n",
    "        news = pop_dict['news']\n",
    "        vnames = pop_dict['v_names']\n",
    "        label=pop_dict['label']\n",
    "        title=pop_dict['title']\n",
    "        #label_score=pop_dict['label_score']\n",
    "\n",
    "        news_list.append(news)\n",
    "        date_list.append(date)\n",
    "        entity_list.append(entity)\n",
    "        vnames_list.append(vnames)\n",
    "        label_list.append(label)\n",
    "        title_list.append(title)\n",
    "        #label_score_list.append(label_score)\n",
    "    return entity_list,news_list, date_list, vnames_list,label_list,label_score_list,title_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "34ba136a-aedb-4945-afc7-75bf4b5c0663",
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchcomment(label_list):\n",
    "    cur_label_list=[]\n",
    "    for label in label_list:\n",
    "        cur_label_list.append(label[0])\n",
    "    return cur_label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b28f3413-2c68-4bab-a8eb-f3918f209849",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalreadlibility(text):\n",
    "    #text=[word,word-.....]为word的列表\n",
    "    test_data = ' '.join(text)\n",
    "    flesch_reading_ease=textstat.flesch_reading_ease(test_data)\n",
    "    smog_index=textstat.smog_index(test_data)\n",
    "    flesch_kincaid_grade=textstat.flesch_kincaid_grade(test_data)\n",
    "    coleman_liau_index=textstat.coleman_liau_index(test_data)\n",
    "    automated_readability_index=textstat.automated_readability_index(test_data)\n",
    "    dale_chall_readability_score=textstat.dale_chall_readability_score(test_data)\n",
    "    difficult_words=textstat.difficult_words(test_data)\n",
    "    linsear_write_formula=textstat.linsear_write_formula(test_data)\n",
    "    gunning_fog=textstat.gunning_fog(test_data)\n",
    "    text_standard=textstat.text_standard(test_data,float_output=True)\n",
    "\n",
    "    return flesch_reading_ease,smog_index,flesch_kincaid_grade,coleman_liau_index,automated_readability_index,dale_chall_readability_score,difficult_words,linsear_write_formula,gunning_fog,text_standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "67c354c2-0b59-482b-adf4-41ba6b9be27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Rouge_score(a,b):\n",
    "    a = ' '.join(a)\n",
    "    b = ' '.join(b)\n",
    "    rouge = Rouge()\n",
    "    rouge_score = rouge.get_scores(a, b)\n",
    "    rouge_1=rouge_score[0][\"rouge-1\"]['r']\n",
    "    rouge_2=rouge_score[0][\"rouge-2\"]['r']\n",
    "    rouge_L=rouge_score[0][\"rouge-l\"]['r']\n",
    "    return rouge_1,rouge_2,rouge_L\n",
    "def Blue_score(a, b):\n",
    "\n",
    "    b = [b]\n",
    "    smooth = bleu_score.SmoothingFunction()\n",
    "    return bleu_score.sentence_bleu(b,a,smoothing_function=smooth.method2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2e0819a5-4faa-41c4-b848-e5efa2214f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedysearch(decoder, max_len, query, vocab):\n",
    "    \"\"\"\n",
    "    a greedy search implementation about seq2seq transformer\n",
    "    :param decoder:\n",
    "    :param max_len: max length of result\n",
    "    :param query: input of Encoder\n",
    "    :param vocab: vocab\n",
    "    :return: list of index\n",
    "    \"\"\"\n",
    "    cnt=0\n",
    "    res=[]\n",
    "    src_ids=[vocab.word2id(word) for word in query]\n",
    "    src = torch.tensor(src_ids).unsqueeze(0)\n",
    "    tgt_ids=[vocab.word2id('[START]')]\n",
    "    while cnt<max_len:\n",
    "        tgt=torch.tensor(tgt_ids).unsqueeze(0)\n",
    "        out=decoder.forward(src,tgt)\n",
    "        cur=out[-1,0,:].argmax().item()\n",
    "        if vocab.id2word(cur)=='[STOP]':\n",
    "            break\n",
    "        tgt_ids.append(cur)\n",
    "        res.append(vocab.id2word(cur))\n",
    "        cnt+=1\n",
    "    return ''.join(res),res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0942dfc1-1348-4438-b730-e7a804c65dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class beamheap:\n",
    "    def __init__(self,vocab,model,Beamsize,backaerfa,foraerfa):\n",
    "        self.vocab=vocab\n",
    "        #self.model=transformer_base(self.vocab,model_params['embed_dim'],model_params['nheads'],pretrained_weight)\n",
    "        self.model=model\n",
    "        self.Beamsize=Beamsize\n",
    "        self.backaerfa=backaerfa#长度惩罚因子\n",
    "        self.foraerfa=foraerfa\n",
    "        \n",
    "    def back_decode(self,batch,tgt_ids,devices):\n",
    "        self.model.eval()\n",
    "        #attention_mask=starattentionmask(src.size(1))\n",
    "        tgt=torch.tensor(tgt_ids).unsqueeze(0)\n",
    "        tgt = tgt.to(device)\n",
    "        _,back_out=self.model(src_ids = batch['src_ids'],\n",
    "                                   back_tgt_ids = tgt,\n",
    "                                   for_tgt_ids = tgt,\n",
    "                                   src_pad_mask = batch['src_pad_mask'],\n",
    "                                   new_list = batch['new_ids'],\n",
    "                                   new_mask = batch['new_ids_mask'],\n",
    "                                   entity = batch['entity'],\n",
    "                                   gpunum = int(devices))\n",
    "        #print(back_out.shape)\n",
    "        return back_out # 输出维度维度是V*1 ，代表每个词出现的概率\n",
    "    \n",
    "    def for_decode(self,batch,tgt_ids,devices):\n",
    "        self.model.eval()\n",
    "        #attention_mask=starattentionmask(src.size(1))\n",
    "        tgt=torch.tensor(tgt_ids).unsqueeze(0)\n",
    "        tgt = tgt.to(device)\n",
    "        \n",
    "        for_out,_=self.model(src_ids = batch['src_ids'],\n",
    "                                   back_tgt_ids = tgt,\n",
    "                                   for_tgt_ids = tgt,\n",
    "                                   src_pad_mask = batch['src_pad_mask'],\n",
    "                                   new_list = batch['new_ids'],\n",
    "                                   new_mask = batch['new_ids_mask'],\n",
    "                                   entity = batch['entity'],\n",
    "                                   gpunum = int(devices))\n",
    "        return for_out # 输出维度维度是V*1 ，代表每个词出现的概率\n",
    "\n",
    "    def fun(self,que,x,dir=None):# 这块维持一个大小为k（Beam search的宽度）的小顶堆，使得复杂度降到log(k)\n",
    "        k=self.Beamsize\n",
    "        if dir == \"back\":\n",
    "            aerfa=self.backaerfa\n",
    "        elif dir == \"for\":\n",
    "            aerfa=self.foraerfa\n",
    "        else:\n",
    "            raise RuntimeError(\"the direction of decode is unlogic\")\n",
    "        que.append(x)\n",
    "        def second(key):# 以序列出现的概率为依据进行排序\n",
    "            p=key[1]\n",
    "            L=len(key[0])\n",
    "            M=math.log(p)/(math.pow( L,aerfa))\n",
    "            return M\n",
    "        que.sort(key=second)\n",
    "        if len(que)>k:\n",
    "            que=que[-k:]\n",
    "        return que"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c12e7056-14a4-40a6-8085-95af59f061a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updatafreq(beams,beamsfreq):\n",
    "    for dic in beams:\n",
    "        word=dic\n",
    "        beamsfreq[word]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "090159a4-263e-47ae-bde4-249894daeb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class beam_search_decoder:\n",
    "    def __init__(self,beamheap,maxlen,numda,minlen):\n",
    "        self.back_decode = beamheap.back_decode#前向decode和后向decode\n",
    "        self.for_decode = beamheap.for_decode\n",
    "        self.topk = beamheap.fun# 这是用于更新当前保留较大的K个备选项的函数\n",
    "        self.vocab = beamheap.vocab\n",
    "        self.maxlen = maxlen\n",
    "        self.beamsize = beamheap.Beamsize\n",
    "        self.numda = numda\n",
    "        self.minlen = minlen\n",
    "    def back_forward(self,batch,entity,devices):# 模型输入为初始向量，一般是编码器的输出\n",
    "        beams = [([entity],1.0)]# 首先把初始向量填入beam中 第一值是输出的序列列表，第二值是该序列出现的概率\n",
    "        beamsfreq=[1 for _ in range(self.vocab.size())]\n",
    "        for itername in range(self.maxlen):# 自回归式迭代生成输出序列 最大输出序列长度为max_len\n",
    "            que = [] # 临时beam缓存\n",
    "            for x,score in beams:# 遍历Beam中所有备选项\n",
    "                if x[-1]==2:#BOS id = 2 如果已经输出了开始字符 则该序列直接用于更新，不再进行解码\n",
    "                    que = self.topk(que,(x,score),'back')\n",
    "                else:\n",
    "                    output = self.back_decode(batch,x,devices) # 以Beam中已生成的序列为输入，生成下一token的概率分布\n",
    "                    output = output[-1,0,:]\n",
    "                    output = F.softmax(output)\n",
    "                    output = output.cpu()\n",
    "                    if self.numda!=0:\n",
    "                        tgt_freq=torch.FloatTensor(beamsfreq)\n",
    "                        tgt_freq=torch.pow(tgt_freq, self.numda)\n",
    "                        tgt_f_vocab=1/tgt_freq\n",
    "                        output=output*tgt_f_vocab\n",
    "                    output=output.tolist()\n",
    "                    beammax=heapq.nlargest(self.beamsize,range(len(output)),output.__getitem__)\n",
    "                    # if itername<self.minlen:\n",
    "\n",
    "                    updatafreq(beammax,beamsfreq)\n",
    "                    for wid in beammax:# 遍历输出选中的beamsize个词\n",
    "                        o_score=output[wid]\n",
    "                        que = self.topk(que,(x+[wid],score*o_score),'back')# 假设改词为输出的词，那么可以得到一个新的序列以及该序列出现的概率\n",
    "            beams = que # 更新Beam\n",
    "        return beams[-1][0]\n",
    "    def for_forward(self,src,back_seq,devices):\n",
    "        beams = [(back_seq,1.0)]# 首先把初始向量填入beam中 第一值是输出的序列列表，第二值是该序列出现的概率\n",
    "        beamsfreq=[1 for _ in range(self.vocab.size())]\n",
    "        for itername in range(self.maxlen):# 自回归式迭代生成输出序列 最大输出序列长度为max_len\n",
    "            que = [] # 临时beam缓存\n",
    "            for x,score in beams:# 遍历Beam中所有备选项\n",
    "                if x[-1]==3:#EOS id = 3 如果已经输出了结束字符 则该序列直接用于更新，不再进行解码\n",
    "                    que = self.topk(que,(x,score),'for')\n",
    "                else:\n",
    "                    output = self.for_decode(src,x,devices) # 以Beam中已生成的序列为输入，生成下一token的概率分布\n",
    "                    output = output[-1,0,:]\n",
    "                    output = F.softmax(output)\n",
    "                    output = output.cpu()\n",
    "                    if self.numda!=0:\n",
    "                        tgt_freq=torch.FloatTensor(beamsfreq)\n",
    "                        tgt_freq=torch.pow(tgt_freq, self.numda)\n",
    "                        tgt_f_vocab=1/tgt_freq\n",
    "                        output=output*tgt_f_vocab\n",
    "                    output=output.tolist()\n",
    "                    beammax=heapq.nlargest(self.beamsize,range(len(output)),output.__getitem__)\n",
    "                    updatafreq(beammax,beamsfreq)\n",
    "                    for wid in beammax:# 遍历输出选中的beamsize个词\n",
    "                        o_score=output[wid]\n",
    "                        que = self.topk(que,(x+[wid],score*o_score),'for')# 假设改词为输出的词，那么可以得到一个新的序列以及该序列出现的概率\n",
    "            beams = que # 更新Beam\n",
    "        return beams[-1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "91364a69-48b8-4460-b71c-a5819df3bd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetname = \"entertainment\"\n",
    "args={\n",
    "    # 数据文件路径\n",
    "    'test_path':\"./data/generate_data/\"+ datasetname + \"_data/\"+ datasetname + \"_test_49500_2gram.json\",\n",
    "    # vocab路径\n",
    "    'vocab_path':\"./data/generate_data/\"+ datasetname + \"_data/\"+ datasetname + \"_vocab_49500_2gram.txt\",\n",
    "    # senti_vocab路径\n",
    "    'senti_vocab_path':\"./data/sentiment_data/\"+ datasetname + \"_data/\"+ datasetname + \"_sentiment_vocab.txt\",\n",
    "    # 词典最大长度\n",
    "    'vocab_len':110000,\n",
    "    'senti_vocab_len':150000,\n",
    "    # 模型保存路径\n",
    "    'checkpoint_path':'./ckpt/',\n",
    "    'history_path':'./history/',\n",
    "    # 情感分析模型路径\n",
    "    'result_model_path':\"./\"+datasetname+\"_ckpt/GModel_steps_250000.pkl\",\n",
    "    # 日志路径\n",
    "    'log_path':'./log/',\n",
    "    # 预训练词embedding模型路径\n",
    "    'embedding_path':'./Word2Vec/word_embedding', \n",
    "    'word_emb_dim':128, # default: 128\n",
    "    'nheads_transformer':4, # embed_dim % nheads_transformer == 0\n",
    "    # 是否使用之前的checkpoint ，0则为不使用\n",
    "    'resume':0,\n",
    "    'model_save_name':'transback_00_2gram_itf_sport',\n",
    "    # only test\n",
    "    'model_resume_name':'',\n",
    "    # 训练batch参数\n",
    "    'batch_size':8,\n",
    "    'end_epoch':100,\n",
    "    'check_steps':1000,\n",
    "    # 模型保存间隔步数\n",
    "    'save_steps':2000,\n",
    "    'lr':1e-4,\n",
    "    # 输出loss间隔步数\n",
    "    'loss_check':300,\n",
    "    # only test\n",
    "    'version_info':'use pretrained embed , encode_layers=6 model.train() revise',\n",
    "    'GPU_ids':'7',\n",
    "    # 学习率递减\n",
    "    'lr_descent':False,\n",
    "    # 最小学习率\n",
    "    'minlr':5e-5,\n",
    "    # 加载预训练好的embedding数据路径\n",
    "    'pretrain_path':\"data/generate_data/\"+ datasetname + \"_data/pretrained_weight_\"+ datasetname + \"_vocab_49500_2gram.npy\",\n",
    "    # 加载预训练好的senti_embedding数据路径\n",
    "    'senti_pretrain_path':\"data/sentiment_data/\"+ datasetname + \"_data/pretrained_weight_\"+ datasetname + \"_sentiment_vocab.npy\",\n",
    "    # 词频字典路径\n",
    "    'freq_path': \"data/generate_data/\"+ datasetname + \"_data/\"+ datasetname + \"_49500_2-gram_labelFre.json\",\n",
    "    # 超参\n",
    "    'numda':0.4,\n",
    "    'gama':0,\n",
    "    'sparse_attention':False,\n",
    "    'devices':'0'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7f1673f1-9396-440e-8fe6-a3075c41135e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = args['test_path']\n",
    "vocab_path = args['vocab_path']\n",
    "senti_vocab_path = args['senti_vocab_path']\n",
    "vocab_len = args['vocab_len']\n",
    "senti_vocab_len = args['senti_vocab_len']\n",
    "resume = args['resume']\n",
    "checkpoint_path = args['checkpoint_path']\n",
    "history_path    = args['history_path']\n",
    "log_path = args['log_path']\n",
    "model_name = args['model_save_name']\n",
    "model_resume_name = args['model_resume_name']\n",
    "batch_size = args['batch_size']\n",
    "end_epoch  = args['end_epoch']\n",
    "lr = args['lr']\n",
    "loss_check_freq = args['loss_check']\n",
    "check_steps= args['check_steps']\n",
    "save_steps = args['save_steps']\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = args['GPU_ids']\n",
    "embedding_path= args['embedding_path']\n",
    "word_emb_dim = args['word_emb_dim']\n",
    "nheads = args['nheads_transformer']\n",
    "minlr= args['minlr']\n",
    "lr_descent= args['lr_descent']\n",
    "pretrain_path= args['pretrain_path']\n",
    "senti_pretrain_path = args['senti_pretrain_path']\n",
    "GPU_ids=args['GPU_ids']\n",
    "numda=args['numda']\n",
    "gama=args['gama']\n",
    "freq_path=args['freq_path']\n",
    "sparse_attention=args['sparse_attention']\n",
    "devices = args['devices']\n",
    "device = torch.device(\"cuda:\"+devices if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0f940196-a7a1-428f-ae2d-76c646e8452d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "09981be6-14d6-453f-8db4-f433ddca6375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] vocab_list读取成功！\n",
      "[INFO] vocab_size: 70678\n",
      "[INFO] Finished constructing vocabulary of %i total words. Last word added: %s 70682 芝迷们\n",
      "[INFO] senti_vocab_list读取成功！\n",
      "[INFO] senti_vocab_size: 72765\n",
      "[INFO] Finished constructing vocabulary of %i total words. Last word added: %s 72769 报国\n"
     ]
    }
   ],
   "source": [
    "#加载生成词典\n",
    "vocab_list=[]\n",
    "for line in open(vocab_path, \"r\",encoding = 'utf-8'):\n",
    "    vocab_list.append(line[:-1])\n",
    "print(\"[INFO] vocab_list读取成功！\")\n",
    "print(\"[INFO] vocab_size:\" , len(vocab_list))\n",
    "# 创建vocab类\n",
    "vocab = Vocab(vocab_list, vocab_len)\n",
    "\n",
    "#加载情感模型词典\n",
    "vocab_list2=[]\n",
    "for line in open(senti_vocab_path, \"r\",encoding = 'utf-8'):\n",
    "    vocab_list2.append(line[:-1])\n",
    "print(\"[INFO] senti_vocab_list读取成功！\")\n",
    "print(\"[INFO] senti_vocab_size:\" , len(vocab_list2))\n",
    "# 创建sentivocab类\n",
    "senti_vocab = Vocab(vocab_list2, senti_vocab_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f21e94f5-d278-4c48-9527-b452c9e4f70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载 生成预训练embed\n",
    "if not os.path.exists(pretrain_path):\n",
    "    print(\"无pretrain,加载中\")\n",
    "    embed_loader = Word_Embedding(embedding_path, vocab)\n",
    "    vectors = embed_loader.load_my_vecs()\n",
    "    pretrained_weight = embed_loader.add_unknown_words_by_uniform(vectors, word_emb_dim)\n",
    "    np.save(pretrain_path,pretrained_weight)\n",
    "    print(\"save完成\")\n",
    "pretrained_weight = np.load(pretrain_path)\n",
    "pretrained_weight = torch.from_numpy(pretrained_weight).to(device)\n",
    "\n",
    "# 加载 情感预训练embed\n",
    "if not os.path.exists(senti_pretrain_path):\n",
    "    print(\"无pretrain,加载中\")\n",
    "    embed_loader = Word_Embedding(embedding_path, senti_vocab)\n",
    "    vectors = embed_loader.load_my_vecs()\n",
    "    senti_pretrained_weight = embed_loader.add_unknown_words_by_uniform(vectors, word_emb_dim)\n",
    "    np.save(senti_pretrain_path,senti_pretrained_weight)\n",
    "    print(\"save完成\")\n",
    "senti_pretrained_weight = np.load(senti_pretrain_path)\n",
    "senti_pretrained_weight = torch.from_numpy(senti_pretrained_weight).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "02556aaf-27e8-46e1-9972-8971bbb2b66a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model : AF_LSTM is ready to run\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "S2sTransformer(\n",
       "  (embedding): Embedding(70682, 128)\n",
       "  (pos_encoder): LearnedPositionEncoding(\n",
       "    500, 128\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (2): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (3): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (4): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (5): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (6): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (7): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (8): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (9): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (10): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (11): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (senti_model): AF_LSTM(\n",
       "    (word_emb): Embedding(72769, 128)\n",
       "    (LSTM_layer): LSTM(128, 128)\n",
       "    (AspectNorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (HiddenNorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (Attention): Self_Attention(\n",
       "      (linear_in): Linear(in_features=128, out_features=128, bias=False)\n",
       "      (tanh): Tanh()\n",
       "      (AWeight): Linear(in_features=128, out_features=1, bias=False)\n",
       "      (softmax): Softmax(dim=1)\n",
       "    )\n",
       "    (rout): Linear(in_features=128, out_features=128, bias=False)\n",
       "    (hout): Linear(in_features=128, out_features=128, bias=False)\n",
       "    (tanh): Tanh()\n",
       "    (classification): Linear(in_features=128, out_features=2, bias=True)\n",
       "    (last_Softmax): Softmax(dim=-1)\n",
       "  )\n",
       "  (memory_linear): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (memory_linear_dropout): Dropout(p=0.1, inplace=False)\n",
       "  (back_decoder): TransformerDecoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (2): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (3): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (4): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (5): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (for_decoder): TransformerDecoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (2): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (3): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (4): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (5): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (output_layer): Linear(in_features=128, out_features=70682, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AFLSTM_model = AF_LSTM(senti_vocab, ifNorm=True, num_layers=1, pretrained_embeddings=senti_pretrained_weight)\n",
    "model = S2sTransformer(vocab, senti_model = AFLSTM_model, word_emb_dim = word_emb_dim, nhead = nheads, pretrained_weight = pretrained_weight)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d04efa38-c191-477f-9f6a-9906262df96d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(args['result_model_path']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e5c02028-1e04-49f2-928a-0b97611134a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/generate_data/entertainment_data/entertainment_test_49500_2gram.json\n"
     ]
    }
   ],
   "source": [
    "print(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fc929c99-1aba-4f5a-a49c-068b1bf4407f",
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = Exampledataset(test_path, vocab,senti_vocab, \"test\",freq_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ae19e8d3-eb11-4ed9-9ef5-0ce3e500cef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'著名主持人'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.id2word(34132)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "461172f0-f7a2-41b7-9daf-561bd33e482d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40551"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.word2id('梅西')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f8b3f15e-6ae2-41b7-99db-e5c7b86328c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c11b036d-bba6-4822-b9f2-f60889fa58fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title_token': [43611, 58669, 62162, 63710, 44907, 8588, 70321, 6947, 27382, 40485, 39146, 16582, 25217, 6604, 53245, 58401, 68465, 35667], 'new_token': [24660, 17579, 12157, 58810, 49667, 17990, 64562, 23593, 64352, 71124, 70254, 26094, 18497, 31017, 9128, 29801, 60147, 795, 25959, 65143, 5633, 26804, 25273, 13560, 47332, 61149, 11056, 5225, 38327, 3493, 49667, 17990, 21445, 20149, 61754, 18497, 43257, 40442, 9489, 64578, 10950, 61656, 43333, 17846, 38787, 62786, 62149, 34792, 4822, 9489, 25388, 72653, 18652, 58810, 28564, 32730, 36259, 61671, 70932, 51628, 7238, 61285, 58810, 19413, 21276, 17846, 58810, 15116, 51931, 72653, 66170, 32091, 48281, 36103, 65930, 58810, 66724, 50270, 58810, 43333, 49340, 12709, 3927, 64493, 52725, 6524, 45812, 58810, 66724, 21276, 43333, 66724, 28300, 45812, 33659, 19372, 37755, 18497, 4791, 9643, 66724, 61754, 21799, 62304, 35724, 37609, 8382, 67224, 60715, 12676, 13435, 59926, 59926, 27600, 11912], 'entity': [58810], 'for_comment_token': [43611, 65378, 61171, 50468, 57380, 50668, 68407, 49719, 58967, 58501, 3], 'back_comment_token': [43611, 2], 'for_comment_freq': [18, 610, 450, 1531, 12, 90, 4, 237, 20, 40, 1], 'back_comment_freq': [18, 1]}\n"
     ]
    }
   ],
   "source": [
    "print(testset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c457421-9e09-4e6e-88e8-42b738f1dfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(testset, batch_size=1,num_workers=4, shuffle=False,collate_fn=collate_func,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1860b058-1f45-4936-94e3-e99367e36f6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b859c63-990f-42dd-a77b-ac70276f8aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Beamsize=6\n",
    "backaerfa=1.7\n",
    "foraerfa=1.38\n",
    "numda=0.6\n",
    "minlen=5\n",
    "comment_maxlen = 20\n",
    "beamsearchheap=beamheap(vocab,model,Beamsize,backaerfa,foraerfa)\n",
    "beam_search_decode=beam_search_decoder(beamsearchheap,comment_maxlen,numda,minlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f23175a-ec2c-4139-be72-81f07644fd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "flesch_reading_ease_score=0\n",
    "smog_index_score=0\n",
    "flesch_kincaid_grade_score=0\n",
    "coleman_liau_index_score=0\n",
    "automated_readability_index_score=0\n",
    "dale_chall_readability_score_score=0\n",
    "difficult_words_score=0\n",
    "linsear_write_formula_score=0\n",
    "gunning_fog_score=0\n",
    "text_standard_score=0\n",
    "rouge_1_list,rouge_2_list,rouge_L_list=0,0,0\n",
    "bleu_list=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fd0b0d-f2ee-41db-8f17-f63d57d68e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "李小冉\n",
      "comment0 predict: 第三部第三部第三部第三部第三部第三部第三部第三部第三部第三部第三部第三部第三部第三部第三部第三部第三部第三部第三部第三部李小冉第三部第三部第三部第三部第三部第三部第三部第三部第三部第三部第三部第三部第三部第三部第三部第三部第三部第三部第三部第三部[STOP]\n",
      "李小冉她为前男友怀孕没结婚后嫁给苦守16年的男闺蜜如今被宠成公主\n",
      "[START]李小冉漂亮但说真话一张苦命脸辨识度[STOP]\n",
      "李菁\n"
     ]
    }
   ],
   "source": [
    "for index, batch in enumerate(test_loader):\n",
    "    src_batch, \\\n",
    "    back_tgt_batch, \\\n",
    "    for_tgt_batch, \\\n",
    "    src_pad_mask, \\\n",
    "    back_tgt_pad_mask, \\\n",
    "    for_tgt_pad_mask, \\\n",
    "    back_tgt_att_mask, \\\n",
    "    for_tgt_att_mask, \\\n",
    "    src_mask_batch, \\\n",
    "    back_tgt_freq_batch, \\\n",
    "    for_tgt_freq_batch , \\\n",
    "    back_tgt_pos_batch, \\\n",
    "    for_tgt_pos_batch , \\\n",
    "    new_ids_batch , \\\n",
    "    new_ids_mask_batch , \\\n",
    "    entity_batch = \\\n",
    "        batch['src_ids'], \\\n",
    "        batch['back_tgt_ids'], \\\n",
    "        batch['for_tgt_ids'], \\\n",
    "        batch['src_pad_mask'], \\\n",
    "        batch['back_tgt_pad_mask'], \\\n",
    "        batch['for_tgt_pad_mask'], \\\n",
    "        batch['back_tgt_mask'], \\\n",
    "        batch['for_tgt_mask'], \\\n",
    "        batch['src_mask'],\\\n",
    "        batch['back_tgt_freq'], \\\n",
    "        batch['for_tgt_freq'], \\\n",
    "        batch['back_tgt_pos'], \\\n",
    "        batch['for_tgt_pos'], \\\n",
    "        batch['new_ids'], \\\n",
    "        batch['new_ids_mask'], \\\n",
    "        batch['entity']\n",
    "    \n",
    "    batch = {k: v.to(device)for k,v in batch.items()}\n",
    "    \n",
    "    entity = batch['entity'].squeeze().item()\n",
    "    entity = vocab.word2id(senti_vocab.id2word(entity))\n",
    "    \n",
    "    print(vocab.id2word(entity))\n",
    "     \n",
    "    # 先生成前向序列\n",
    "    prefix_comment=beam_search_decode.back_forward(batch,entity,devices)\n",
    "    # 逆序\n",
    "    prefix_comment=prefix_comment[::-1]\n",
    "    # labellist = []\n",
    "    # for word in prefix_comment:\n",
    "    #     labellist.append(vocab.id2word(word))\n",
    "    # print(labellist)\n",
    "    # 生成后向序列\n",
    "    complete_comment=beam_search_decode.for_forward(batch,prefix_comment,devices)\n",
    "    if complete_comment[-1]!=3:\n",
    "        complete_comment.append(3)\n",
    "    complete_comment=[vocab.id2word(cur) for cur in complete_comment]\n",
    "\n",
    "    print('comment'+str(index)+' predict:',''.join(complete_comment))\n",
    "\n",
    "    title = testset[index]['title_token']\n",
    "    titlelist = []\n",
    "    for word in title:\n",
    "        titlelist.append(vocab.id2word(word))\n",
    "    title = ''.join(titlelist)\n",
    "    print(title)\n",
    "    \n",
    "    back_label = testset[index]['back_comment_token']\n",
    "    for_label = testset[index]['for_comment_token']\n",
    "    back_label = back_label[::-1]\n",
    "    label = back_label[:-1]+for_label\n",
    "    labellist = []\n",
    "    for word in label:\n",
    "        labellist.append(vocab.id2word(word))\n",
    "        \n",
    "    label = ''.join(labellist)\n",
    "    print(label)\n",
    "    # label.insert(0,\"[START]\")\n",
    "    # label.append(\"[STOP]\")\n",
    "    # predict.insert(0,\"[START]\")\n",
    "    # predict.append(\"[STOP]\")\n",
    "\n",
    "    #print('labels',index,''.join(label))\n",
    "    flesch_reading_ease,\\\n",
    "    smog_index,\\\n",
    "    flesch_kincaid_grade,\\\n",
    "    coleman_liau_index,\\\n",
    "    automated_readability_index,\\\n",
    "    dale_chall_readability_score,\\\n",
    "    difficult_words,\\\n",
    "    linsear_write_formula,\\\n",
    "    gunning_fog,\\\n",
    "    text_standard=evalreadlibility(complete_comment)\n",
    "    rouge_1,rouge_2,rouge_L=Rouge_score(complete_comment,label)\n",
    "    bleu=Blue_score(complete_comment,label)\n",
    "    bleu_list+=bleu\n",
    "    rouge_1_list+=rouge_1\n",
    "    rouge_2_list+=rouge_2\n",
    "    rouge_L_list+=rouge_L\n",
    "    flesch_reading_ease_score+=flesch_reading_ease\n",
    "    smog_index_score+=smog_index\n",
    "    flesch_kincaid_grade_score+=flesch_kincaid_grade\n",
    "    coleman_liau_index_score+=coleman_liau_index\n",
    "    automated_readability_index_score+=automated_readability_index\n",
    "    dale_chall_readability_score_score+=dale_chall_readability_score\n",
    "    difficult_words_score+=difficult_words\n",
    "    linsear_write_formula_score+=linsear_write_formula\n",
    "    gunning_fog_score+=gunning_fog\n",
    "    text_standard_score+=text_standard\n",
    "n_iter=len(news_list)\n",
    "print(\"rouge_1:\",rouge_1_list/n_iter)\n",
    "print(\"rouge_2:\",rouge_2_list/n_iter)\n",
    "print(\"rouge_L:\",rouge_L_list/n_iter)\n",
    "print(\"bleu:\",bleu_list/n_iter)\n",
    "print(\"flesch_reading_ease_score:\",flesch_reading_ease_score/n_iter)\n",
    "print(\"smog_score:\",smog_index_score/n_iter)\n",
    "print(\"flesch_kincaid_grade_score:\",flesch_kincaid_grade_score/n_iter)\n",
    "print(\"coleman_liau_index_score:\",coleman_liau_index_score/n_iter)\n",
    "print(\"automated_readability_score:\",automated_readability_index_score/n_iter)\n",
    "print(\"dale_chall_readability_score:\",dale_chall_readability_score_score/n_iter)\n",
    "print(\"difficult_words_score:\",difficult_words_score/n_iter)\n",
    "print(\"gunning_fog_score:\",gunning_fog_score/n_iter)\n",
    "print(\"linsear_write_formula_score:\",linsear_write_formula_score/n_iter)\n",
    "print(\"text_standard_score:\",text_standard_score/n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3e2035-d050-432d-a7e5-6aa603a0a216",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c226cdf1-2772-42df-9bba-d0d3d6469f86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
